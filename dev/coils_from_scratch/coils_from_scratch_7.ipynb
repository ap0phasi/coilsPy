{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building coilsPy from scratch "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Normalized Generation Scheme\n",
    "First we need a reliable way of generating a tensor of complex numbers that sum to be some specified point along the complex unit circle. To help, let's use a simple function to plot out complex tensors tip-to-tail to ensure they meet this criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_complex_vectors(complex_array):\n",
    "    # Plot the unit circle\n",
    "    angles = np.linspace(0, 2 * np.pi, 100)\n",
    "    plt.plot(np.cos(angles), np.sin(angles), linestyle='dotted')\n",
    "\n",
    "    # Starting point for the vectors\n",
    "    start = 0 + 0j\n",
    "    for z in complex_array:\n",
    "        # Plot each vector\n",
    "        end = start + z\n",
    "        plt.arrow(start.real, start.imag, z.real, z.imag,\n",
    "                  head_width=0.05, head_length=0.05, length_includes_head=True)\n",
    "        start = end\n",
    "\n",
    "    # Set equal scaling and labels\n",
    "    plt.axis('equal')\n",
    "    plt.xlabel('Real')\n",
    "    plt.ylabel('Imaginary')\n",
    "    plt.grid(True)\n",
    "    plt.title('Complex Vectors Summation')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Kernels\n",
    "\n",
    "For creating dirichlet distributions we will introduce some kernel options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a number of ways I can accomplish our needs, but currently I am using the following approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def generate_rbf(length, center_index, sigma):\n",
    "    \"\"\"\n",
    "    Generates a 1D radial basis function (Gaussian) of specified width centered on a given index.\n",
    "\n",
    "    Parameters:\n",
    "    length (int): The length of the output tensor.\n",
    "    center_index (int): The index at which the RBF is centered.\n",
    "    sigma (float): The standard deviation (width) of the RBF.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: A 1D tensor representing the radial basis function.\n",
    "    \"\"\"\n",
    "    if center_index >= length or center_index < 0:\n",
    "        raise ValueError(\"Center index must be within the range of the tensor length.\")\n",
    "\n",
    "    # Create an array of indices\n",
    "    x = torch.arange(0, length, dtype=torch.float32)\n",
    "\n",
    "    # Calculate the RBF\n",
    "    rbf = torch.exp(-0.5 * ((x - center_index) / sigma) ** 2)\n",
    "\n",
    "    return rbf\n",
    "\n",
    "def generate_kernel(length, center_index, type = \"rbf\", restrictions = [], **kwargs):\n",
    "    if type == \"rbf\":\n",
    "        kernel = generate_rbf(length, center_index, kwargs['sigma'])\n",
    "        \n",
    "    # Replace zero values with min_value\n",
    "    kernel = torch.where(kernel == 0, torch.tensor(1e-10, dtype=kernel.dtype), kernel)\n",
    "    \n",
    "    # Set restrictions to 0\n",
    "    kernel[restrictions] = 1e-10\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "\n",
    "# Example usage\n",
    "length = 10  # Length of the tensor\n",
    "center_index = 5  # Center the RBF at index 5\n",
    "sigma = 0.01  # Standard deviation of the RBF\n",
    "\n",
    "rbf_tensor = generate_kernel(length, center_index, type = \"rbf\", sigma=sigma)\n",
    "\n",
    "# Plotting the RBF\n",
    "plt.scatter(torch.arange(length), rbf_tensor)\n",
    "plt.title(\"Radial Basis Function (RBF)\")\n",
    "plt.xlabel(\"Index\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_array_to_target_torch(tensor, target_sum):\n",
    "    # Create a mask for non-zero elements\n",
    "    non_zero_mask = tensor > 1e-5\n",
    "\n",
    "    # Calculate the sum of non-zero elements\n",
    "    sum_non_zero = torch.sum(tensor[non_zero_mask])\n",
    "\n",
    "    # Count the non-zero elements\n",
    "    count_non_zero = torch.sum(non_zero_mask)\n",
    "    \n",
    "    # Avoid division by zero in case all elements are zero\n",
    "    if count_non_zero == 0:\n",
    "        return tensor\n",
    "\n",
    "    # Calculate the required adjustment to reach the target sum\n",
    "    adjustment = (target_sum - sum_non_zero) / count_non_zero\n",
    "    \n",
    "    # Add the adjustment to each non-zero element\n",
    "    tensor[non_zero_mask] += adjustment\n",
    "\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributions.Dirichlet(torch.tensor([5.1, 0.5])).sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def dirichlet_to_goal(goal_value, num_elements, center_index, sigma, magnitude, restrictions):\n",
    "    # Generate alphas for dirichlet\n",
    "    alphas = generate_kernel(length = num_elements, center_index = center_index, type = \"rbf\", sigma = sigma, restrictions = restrictions) * magnitude\n",
    "    rand_samples = torch.distributions.Dirichlet(alphas).sample()\n",
    "    \n",
    "    rand_samples = rescale_array_to_target_torch(rand_samples, goal_value)\n",
    "    \n",
    "    return rand_samples\n",
    "\n",
    "def generate_complex_sum(goal_theta, num_elements, center_index_re, center_index_im, sigma_re, sigma_im, magnitude_re, magnitude_im, restrictions = []):\n",
    "    real_goal = torch.cos(goal_theta)\n",
    "    imag_goal = torch.sin(goal_theta)\n",
    "    real_parts = dirichlet_to_goal(1, num_elements, center_index_re, sigma_re, magnitude_re, restrictions)\n",
    "    imag_parts = dirichlet_to_goal(0, num_elements, center_index_im, sigma_im, magnitude_im, restrictions)\n",
    "    complex_numbers = torch.complex(real_parts, imag_parts)\n",
    "    \n",
    "    # Step 4: Rotate the entire set of vectors by the goal theta\n",
    "    rotated_complex_numbers = complex_numbers * (real_goal + imag_goal * 1j)\n",
    "    \n",
    "    rotated_complex_numbers = torch.tensor(rotated_complex_numbers, dtype=torch.complex128)\n",
    "\n",
    "    return rotated_complex_numbers\n",
    "\n",
    "# Example usage\n",
    "theta = torch.tensor([0.3 * torch.pi])  # 90 degrees, should sum to i\n",
    "complex_array = generate_complex_sum(theta, \n",
    "                                     num_elements = 5, \n",
    "                                     center_index_re = 0, \n",
    "                                     center_index_im = 0, \n",
    "                                     sigma_re = 1e100, \n",
    "                                     sigma_im = 1e100, \n",
    "                                     magnitude_re = 1, \n",
    "                                     magnitude_im = 1,\n",
    "                                     restrictions = [])\n",
    "plot_complex_vectors(complex_array.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirichlet_to_goal(0, num_elements = 4, center_index=0, sigma=100, magnitude = 1, restrictions = [1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Renormalization\n",
    "\n",
    "In theory, the previous steps should ensure conservation. However, even when using a precision of complex128, there are still memory errors that cause us to lose conservation. Therefore we can optionally renormalize. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renormalize_to_unit_circle(array):\n",
    "    \"\"\"\n",
    "    Renormalizes an array of complex numbers so that it sums to a point on the unit circle.\n",
    "\n",
    "    Parameters:\n",
    "    array (torch.Tensor): A 1D tensor of complex numbers.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: A renormalized 1D tensor of complex numbers.\n",
    "    \"\"\"\n",
    "    current_sum = torch.sum(array)\n",
    "    if current_sum == 0:\n",
    "        return array  # Avoid division by zero if the current sum is 0\n",
    "\n",
    "    # Calculate the magnitude of the current sum\n",
    "    magnitude = torch.abs(current_sum)\n",
    "\n",
    "    # Calculate the scale factor\n",
    "    scale_factor = 1 / magnitude\n",
    "\n",
    "    # Renormalize the array\n",
    "    renormalized_array = array * scale_factor\n",
    "\n",
    "    return renormalized_array\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial State Generation\n",
    "\n",
    "This function alone is sufficient for generating our initial state, so let's make some helper functions to generate our initial transition tensor and interaction tensor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transition tensor create:\n",
    "def initialize_transition_tensor(num_elements, theta, restrict_dict = []):\n",
    "    # Create a list to store each column\n",
    "    columns = []\n",
    "    num_columns = num_elements\n",
    "\n",
    "    for col in range(num_columns):\n",
    "        \n",
    "        if col in restrict_dict:\n",
    "            restrictions = restrict_dict[col]\n",
    "        else:\n",
    "            restrictions = []\n",
    "                    \n",
    "        column = generate_complex_sum(theta, \n",
    "                    num_elements = num_elements, \n",
    "                    center_index_re = col, \n",
    "                    center_index_im = 0, \n",
    "                    sigma_re = 0.4, \n",
    "                    sigma_im = 1e10, \n",
    "                    magnitude_re = 1.0, \n",
    "                    magnitude_im = 100.0,\n",
    "                    restrictions = restrictions)\n",
    "        columns.append(column.unsqueeze(1))  # Add a dimension to make it a column\n",
    "\n",
    "    # Combine columns into a matrix\n",
    "    transition_tensor = torch.cat(columns, dim=1)\n",
    "    \n",
    "    return transition_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction Tensor Create:\n",
    "def initialize_interaction_tensor(num_elements, theta, restrict_dict = []):\n",
    "    # Example usage\n",
    "    num_3d_tensors = num_elements + 1  # Number of 3D tensors in the 4D tensor\n",
    "    num_matrices = num_elements  # Number of 2D matrices in each 3D tensor\n",
    "    num_columns = num_elements  # Number of columns in each 2D matrix\n",
    "\n",
    "    # Create a list to store each 3D tensor\n",
    "    tensors_3d = []\n",
    "\n",
    "    for _ in range(num_3d_tensors):\n",
    "        matrices = []\n",
    "        for _ in range(num_matrices):\n",
    "            columns = []\n",
    "            for col in range(num_columns):\n",
    "                \n",
    "                if col in restrict_dict:\n",
    "                    restrictions = restrict_dict[col]\n",
    "                else:\n",
    "                    restrictions = []\n",
    "                    \n",
    "                column = generate_complex_sum(theta, \n",
    "                                    num_elements = num_elements, \n",
    "                                    center_index_re = col, \n",
    "                                    center_index_im = 0, \n",
    "                                    sigma_re = 0.4, \n",
    "                                    sigma_im = 1e10, \n",
    "                                    magnitude_re = 1.0, \n",
    "                                    magnitude_im = 100.0,\n",
    "                                    restrictions = restrictions)\n",
    "                columns.append(column.unsqueeze(1))  # Add a dimension to make it a column\n",
    "            matrix = torch.cat(columns, dim=1)\n",
    "            matrices.append(matrix)  # Add a dimension to make it a 2D matrix\n",
    "        tensor_3d = torch.stack(matrices, dim=2)\n",
    "        tensors_3d.append(tensor_3d)\n",
    "\n",
    "    # Combine 3D tensors into a 4D tensor\n",
    "    # Stack along the fourth dimension\n",
    "    interaction_tensor = torch.stack(tensors_3d, dim=3)\n",
    "    \n",
    "    return interaction_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can generate all the starting states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elements = 5\n",
    "\n",
    "# Thetas for state, transition, and interactions\n",
    "angles_dict = {\n",
    "    'state': 0.3,\n",
    "    'transition': 0.2,\n",
    "    'interaction': 0.4\n",
    "}\n",
    "\n",
    "# Set restrictions\n",
    "\n",
    "# Local\n",
    "restrict_dict = {\n",
    "    0: [2, 3, 4],\n",
    "    1: [3, 4],\n",
    "    2: [0, 4],\n",
    "    3: [0, 1],\n",
    "    4: [0, 1, 2]\n",
    "}\n",
    "\n",
    "# Grouping\n",
    "# restrict_dict = {\n",
    "#     0: [2, 3, 4],\n",
    "#     1: [2, 3, 4],\n",
    "#     2: [0, 1],\n",
    "#     3: [0, 1],\n",
    "#     4: [0, 1]\n",
    "# }\n",
    "\n",
    "# No restrictions\n",
    "# restrict_dict = {}\n",
    "\n",
    "thetas_dict = {key : torch.tensor([value * torch.pi]) for key, value in angles_dict.items()}\n",
    "\n",
    "# Establish state_tensor\n",
    "state_tensor = generate_complex_sum(theta, \n",
    "                                     num_elements = num_elements, \n",
    "                                     center_index_re = 0, \n",
    "                                     center_index_im = 0, \n",
    "                                     sigma_re = 1e100, \n",
    "                                     sigma_im = 1e100, \n",
    "                                     magnitude_re = 1, \n",
    "                                     magnitude_im = 100,\n",
    "                                     restrictions = [])\n",
    "transition_tensor = initialize_transition_tensor(theta = thetas_dict['transition'], num_elements = num_elements, restrict_dict=restrict_dict)\n",
    "interaction_tensor = initialize_interaction_tensor(theta = thetas_dict['transition'], num_elements = num_elements, restrict_dict=restrict_dict)\n",
    "\n",
    "# Move everything to GPU\n",
    "state_tensor = state_tensor.to('cuda:0')\n",
    "transition_tensor = transition_tensor.to('cuda:0')\n",
    "interaction_tensor = interaction_tensor.to('cuda:0')\n",
    "\n",
    "state_tensor.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(transition_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subvec = state_tensor[0] + state_tensor[1]\n",
    "subvec * torch.conj(subvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CUDA GPU:\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization testing\n",
    "Let's first do some quick tests to make sure our normalization is working as intended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First just checking that our initial transition tensor looks good:\n",
    "new_state_tensor = torch.matmul(transition_tensor,state_tensor)\n",
    "\n",
    "plot_complex_vectors(new_state_tensor.to('cpu').numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we check that our interaction tensor works as intended\n",
    "sel_state = 1\n",
    "\n",
    "if sel_state == 0:\n",
    "    selected_normalized_tensor = state_tensor\n",
    "else:\n",
    "    selected_normalized_tensor = transition_tensor[:,sel_state-1]\n",
    "    \n",
    "selected_interaction_tensor = interaction_tensor[:,:,:,sel_state]\n",
    "\n",
    "new_transition_tensor = torch.matmul(selected_interaction_tensor, selected_normalized_tensor)\n",
    "\n",
    "print(new_transition_tensor)\n",
    "\n",
    "new_state_tensor = torch.matmul(new_transition_tensor, state_tensor)\n",
    "\n",
    "plot_complex_vectors(new_state_tensor.to('cpu').numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = torch.matmul(selected_interaction_tensor, selected_normalized_tensor)[:,1]\n",
    "sum(check * torch.conj(sum(check)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = selected_interaction_tensor[:,:,1]\n",
    "sum(check * torch.conj(sum(check)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_add(tensor):\n",
    "    return torch.abs(torch.real(tensor)+torch.imag(tensor))\n",
    "\n",
    "complex_add(torch.complex(torch.tensor([5.0, 3.0]), torch.tensor([-2.0, 2.0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that this is workign as intended, let's make our function to select the normalized subgroup and associated transition matrix that will maximize the probability from going from the largest state to the smallest state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_transition_tensor(state_tensor,transition_tensor,interaction_tensor):\n",
    "    # First we need to know which transition point we are looking for\n",
    "    state_magnitudes = complex_add(state_tensor)\n",
    "    state_magnitudes_order = torch.argsort(state_magnitudes)\n",
    "    to_index = state_magnitudes_order[0] # The smallest state magnitude\n",
    "    from_index = state_magnitudes_order[-1] # The largest state magnitude\n",
    "    \n",
    "    # Next we need to go through each possible normalized subgroup and determine which one we should use\n",
    "    new_transitions = []\n",
    "    for sel_state in range(state_tensor.shape[0]):\n",
    "        if sel_state == 0:\n",
    "            selected_normalized_tensor = state_tensor\n",
    "        else:\n",
    "            selected_normalized_tensor = transition_tensor[:,sel_state-1]\n",
    "            \n",
    "        selected_interaction_tensor = interaction_tensor[:,:,:,sel_state]\n",
    "\n",
    "        new_transition_tensor = torch.matmul(selected_interaction_tensor,selected_normalized_tensor)\n",
    "        \n",
    "        new_transitions.append(new_transition_tensor)\n",
    "        \n",
    "     # Convert list of tensors to a tensor\n",
    "    new_transitions_tensor = torch.stack(new_transitions)\n",
    "    \n",
    "    sorted_indices = torch.argsort(complex_add(new_transitions_tensor[:, to_index, from_index]), descending=True)\n",
    "    selected_subgroup = sorted_indices[0]\n",
    "    \n",
    "    return new_transitions[selected_subgroup], selected_subgroup\n",
    "\n",
    "select_transition_tensor(state_tensor,transition_tensor,interaction_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we just need to step through the coil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "\n",
    "num_steps = 100\n",
    "prob_save = []\n",
    "\n",
    "print(f\"substate starting total: {sum(torch.real(state_tensor * torch.conj(state_tensor.sum()))[:2])}\")\n",
    "for i_step in range(num_steps):\n",
    "    transition_tensor, selected_subgroup = select_transition_tensor(state_tensor,transition_tensor,interaction_tensor)\n",
    "    \n",
    "    state_tensor = torch.matmul(transition_tensor,state_tensor)\n",
    "    \n",
    "    plot_complex_vectors(state_tensor.to('cpu').numpy())\n",
    "    \n",
    "    # Optionally we can renomalize to avoid memory errors\n",
    "    state_tensor = renormalize_to_unit_circle(state_tensor)\n",
    "    \n",
    "    state_prob = torch.real(state_tensor * torch.conj(state_tensor.sum()))\n",
    "    \n",
    "    prob_save.append(state_prob)\n",
    "    \n",
    "    #print(state_prob[0]+state_prob[1])\n",
    "    #print(state_prob.sum())\n",
    "    # print(selected_subgroup)\n",
    "    \n",
    "    #plot_complex_vectors(state_tensor.to('cpu').numpy())\n",
    "    \n",
    "toc = time.time()    \n",
    "print(f\"substate ending total: {sum(torch.real(state_tensor * torch.conj(state_tensor.sum()))[:2])}\")\n",
    "\n",
    "print(f\"Processing time: {round(toc-tic,4)}s\")\n",
    "print(state_prob.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your data\n",
    "data = [row.to('cpu') for row in prob_save]\n",
    "# Transpose the data to get 5 traces\n",
    "traces = list(zip(*data))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, trace in enumerate(traces):\n",
    "    plt.plot(trace, label=f'Trace {i+1}')\n",
    "\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_tensor.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
