{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0966, 0.0143, 0.2557, 0.0420, 0.2699, 0.3216],\n",
      "        [0.2561, 0.0221, 0.1642, 0.1490, 0.2198, 0.1888],\n",
      "        [0.0931, 0.1505, 0.2764, 0.2581, 0.0254, 0.1965],\n",
      "        [0.1804, 0.1271, 0.1946, 0.1877, 0.2196, 0.0906],\n",
      "        [0.0242, 0.0941, 0.1834, 0.2081, 0.1398, 0.3503]])\n",
      "tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000])\n"
     ]
    }
   ],
   "source": [
    "def torch_randnorm(size, dim=0):\n",
    "    # Generate a random tensor\n",
    "    rand_tensor = torch.rand(size)\n",
    "    \n",
    "    # Normalize along the specified dimension\n",
    "    sum_along_dim = torch.sum(rand_tensor, dim=dim, keepdim=True)\n",
    "    normalized_tensor = rand_tensor / sum_along_dim\n",
    "    \n",
    "    return normalized_tensor\n",
    "\n",
    "# Example usage\n",
    "normalized_tensor = torch_randnorm([5,6], dim=1)\n",
    "print(normalized_tensor)\n",
    "print(normalized_tensor.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InteractionModule(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(InteractionModule, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        # Initialize a set of interaction tensors, one for the state tensor and one for each column of the transition tensor\n",
    "        self.interaction_tensors = nn.ParameterList([nn.Parameter(torch_randnorm([n_features, n_features, n_features], dim = 1)) for _ in range(n_features + 1)])\n",
    "\n",
    "    def forward(self, state_tensor, previous_transition_tensor):\n",
    "        # Get batch size\n",
    "        batch = state_tensor.shape[0]\n",
    "        # Assuming previous_transition_tensors is a list of transition tensors from the previous step\n",
    "        candidates = []\n",
    "        for i in range(self.n_features + 1):\n",
    "            if i == 0:  # Interaction with the state tensor\n",
    "                current_tensor = state_tensor\n",
    "            else:  # Interaction with columns of the previous transition tensor\n",
    "                current_tensor = previous_transition_tensor[:, :, i - 1]\n",
    "\n",
    "            interaction_tensor = self.interaction_tensors[i]\n",
    "            current_tensor_expanded = current_tensor.unsqueeze(1).expand(-1, self.n_features, -1)  # Shape: [batch, n_features, n_features]\n",
    "            interaction_tensor_expanded = interaction_tensor.unsqueeze(0).expand(batch, -1, -1, -1)  # Shape: [batch, n_features, n_features, n_features]\n",
    "            # Multiply and sum over the last dimension to get the transition tensor\n",
    "            candidate = torch.einsum('bik,bijk->bij', current_tensor_expanded, interaction_tensor_expanded)\n",
    "            \n",
    "            candidates.append(candidate)\n",
    "            \n",
    "        candidates_tensor = torch.stack(candidates, dim = -1)\n",
    "        return candidates_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "class SelectorModule(nn.Module):\n",
    "    def __init__(self, num_slices):\n",
    "        super(SelectorModule, self).__init__()\n",
    "        # A simple linear layer to compute importance scores for each slice\n",
    "        self.importance = nn.Linear(num_slices, num_slices)\n",
    "\n",
    "    def forward(self, x, temperature=1):\n",
    "        # Assuming x is of shape [batch_size, height, width, num_slices]\n",
    "        batch_size, _, _, num_slices = x.shape\n",
    "\n",
    "        # Compute importance scores by reducing x across spatial dimensions\n",
    "        # Here, we take the mean of x across the spatial dimensions to get a vector per slice\n",
    "        x_reduced = x.mean(dim=[1, 2])  # Shape: [batch_size, num_slices]\n",
    "\n",
    "        # Compute scores for each slice\n",
    "        scores = self.importance(x_reduced)  # Shape: [batch_size, num_slices]\n",
    "        \n",
    "        # Apply Gumbel-Softmax to approximate a discrete selection of slices\n",
    "        weights = F.gumbel_softmax(scores, tau=temperature, hard=False, dim=-1)\n",
    "        #weights = torch.softmax(scores,dim=-1)\n",
    "        #print(weights)\n",
    "        # Correct application of weights:\n",
    "        # We need to ensure weights are applied across the num_slices dimension correctly.\n",
    "        # Since weights are [batch_size, num_slices] and x is [batch_size, height, width, num_slices],\n",
    "        # we permute x to bring num_slices to the front for broadcasting.\n",
    "        x_permuted = x.permute(0, 3, 1, 2)  # Shape: [batch_size, num_slices, height, width]\n",
    "        \n",
    "        # Now, multiply by weights. We need to reshape weights to [batch_size, num_slices, 1, 1] for broadcasting.\n",
    "        weighted_slices = x_permuted * weights.view(batch_size, num_slices, 1, 1)\n",
    "        \n",
    "        # Finally, sum the weighted slices across the num_slices dimension (now the first dimension after permute)\n",
    "        selected = weighted_slices.sum(dim=1)  # Shape: [batch_size, height, width]\n",
    "\n",
    "        return selected\n",
    "\n",
    "# Example usage\n",
    "batch_size = 10\n",
    "tensor = torch.rand(batch_size, 5, 5, 6)  # Example tensor\n",
    "model = SelectorModule(num_slices=6)\n",
    "\n",
    "result = model(tensor)\n",
    "print(result.shape)  # Should print torch.Size([10, 5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCoilLayer(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(NeuralCoilLayer, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.interaction_module = InteractionModule(n_features)\n",
    "        self.selector_module = SelectorModule(n_features + 1)\n",
    "        \n",
    "    def step_coil(self, state_tensor, previous_transition_tensor):\n",
    "        # Generate candidates\n",
    "        candidates = self.interaction_module(state_tensor, previous_transition_tensor)\n",
    "        # Select one candidate\n",
    "        selected_transition_tensor = self.selector_module(candidates)\n",
    "        \n",
    "        new_state_tensor = torch.matmul(selected_transition_tensor, state_tensor.unsqueeze(-1)).squeeze(-1)\n",
    "        \n",
    "        return new_state_tensor, selected_transition_tensor\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, length, n_features = x.size()\n",
    "        output = x.new_empty(batch, length, n_features)\n",
    "\n",
    "        # Initialize previous transition tensors (for the first step)\n",
    "        # Assuming it's a list of zero tensors for simplicity\n",
    "        transition_tensor = torch.zeros(batch, n_features, n_features)\n",
    "\n",
    "        for l in range(length):\n",
    "            state_tensor = x[:, l, :]\n",
    "            \n",
    "            # Compute output for this step\n",
    "            output[:, l, :], transition_tensor = self.step_coil(state_tensor, transition_tensor)\n",
    "\n",
    "        return output, transition_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 64, 16])\n"
     ]
    }
   ],
   "source": [
    "n_features = 16\n",
    "batch, length, dim = 13, 64, n_features\n",
    "x = torch.randn(batch, length, dim)\n",
    "model = NeuralCoilLayer(\n",
    "    n_features = n_features\n",
    ")\n",
    "y = model(x)\n",
    "\n",
    "print(y[0].shape)\n",
    "assert y[0].shape == x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perpetuation Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0045,  0.0068, -0.0005,  0.0030,  0.0029,  0.0057,  0.0088,  0.0014,\n",
       "         0.0010, -0.0017,  0.0041,  0.0032, -0.0030,  0.0022,  0.0006, -0.0015],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 16\n",
    "batch, length, dim = 13, 64, n_features\n",
    "x = torch.randn(batch, length, dim)\n",
    "model = NeuralCoilLayer(\n",
    "    n_features = n_features\n",
    ")\n",
    "\n",
    "l = 1\n",
    "state_tensor = x[:, l, :]\n",
    "transition_tensor = torch.zeros(batch, n_features, n_features)\n",
    "\n",
    "y = model.step_coil(state_tensor, transition_tensor)\n",
    "y[0][1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the same as if we just look at the batches independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0284,  0.0425, -0.0034,  0.0188,  0.0179,  0.0359,  0.0551,  0.0085,\n",
       "         0.0062, -0.0109,  0.0255,  0.0203, -0.0186,  0.0136,  0.0038, -0.0095],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = 2\n",
    "l = 1\n",
    "state_tensor = x[0:2, l, :]\n",
    "transition_tensor = torch.zeros(batch, n_features, n_features)\n",
    "\n",
    "y = model.step_coil(state_tensor, transition_tensor)\n",
    "y[0][1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't the same, so something is wrong with this development"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coilspy-1sgZ1XBf-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
