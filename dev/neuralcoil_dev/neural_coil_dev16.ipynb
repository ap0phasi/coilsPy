{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_randnorm(size, dim=0):\n",
    "    # Generate a random tensor\n",
    "    rand_tensor = torch.rand(size)\n",
    "    \n",
    "    # Normalize along the specified dimension\n",
    "    sum_along_dim = torch.sum(rand_tensor, dim=dim, keepdim=True)\n",
    "    normalized_tensor = rand_tensor / sum_along_dim\n",
    "    \n",
    "    return normalized_tensor\n",
    "\n",
    "# Example usage\n",
    "normalized_tensor = torch_randnorm([5,6], dim=1)\n",
    "print(normalized_tensor)\n",
    "print(normalized_tensor.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralCoilLayer(nn.Module):\n",
    "    def __init__(self, n_features):\n",
    "        super(NeuralCoilLayer, self).__init__()\n",
    "        self.n_features = n_features\n",
    "        self.attention_weights = nn.Linear(n_features, 1, bias=False)\n",
    "        self.act = nn.SiLU()\n",
    "        self.interaction_tensors = nn.Parameter(torch.randn(n_features, n_features, n_features, n_features + 1))\n",
    "        self.topk_num = 1\n",
    "        \n",
    "    def step_coil(self, state_tensor, previous_transition_tensor):\n",
    "        # Establish normalized subgroups\n",
    "        norm_subgroups = torch.cat((state_tensor.unsqueeze(-2), previous_transition_tensor), dim=1)\n",
    "        batch_size, num_groups, n_features = norm_subgroups.shape\n",
    "        \n",
    "        # Compute scores for each normalized subgroup\n",
    "        scores = self.act(self.attention_weights(norm_subgroups)).sum(-1) # [batch_size, num_groups]\n",
    "        \n",
    "        weights = torch.softmax(scores,dim = -1) # [batch_size, num_groups]\n",
    "        \n",
    "        selected_interaction_tensors = self.interaction_tensors\n",
    "        selected_norm_subgroups = norm_subgroups\n",
    "\n",
    "        #selected_transition_tensors = torch.einsum('ijks,bsi->bjks', selected_interaction_tensors, selected_norm_subgroups)\n",
    "        \n",
    "        selected_transition_tensors = (torch.mul(selected_interaction_tensors, selected_norm_subgroups.permute(0,2,1).unsqueeze(1).unsqueeze(1))).sum(-2)\n",
    "        \n",
    "        # We need a single transition tensor so we will average this as well\n",
    "        #selected_transition_tensor = torch.einsum('bs,bjks->bjk', weights,selected_transition_tensors)\n",
    "        \n",
    "        selected_transition_tensor = (torch.mul(selected_transition_tensors, weights.unsqueeze(-2).unsqueeze(-2))).sum(-1)\n",
    "        # Generate state tensor from the transition tensor\n",
    "        # Unsqueezing state_tensor to make it [batch_size, n_features, 1] for matrix multiplication\n",
    "        state_tensor_unsqueezed = state_tensor.unsqueeze(2)\n",
    "\n",
    "        # Performing batch matrix multiplication\n",
    "        new_state_tensor_bmm = torch.bmm(selected_transition_tensor, state_tensor_unsqueezed)\n",
    "\n",
    "        # Squeezing the result to get rid of the extra dimension, resulting in [batch_size, n_features]\n",
    "        new_state_tensor = new_state_tensor_bmm.squeeze(2)\n",
    "    \n",
    "        softmax_tensor = torch.softmax(new_state_tensor * n_features, dim = 1)\n",
    "        \n",
    "        return softmax_tensor, selected_transition_tensor\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch, length, n_features = x.size()\n",
    "        output = x.new_empty(batch, length, n_features)\n",
    "\n",
    "        # Initialize previous transition tensors (for the first step)\n",
    "        # Assuming it's a list of zero tensors for simplicity\n",
    "        transition_tensor = torch.zeros(batch, n_features, n_features).to(\"cuda\")\n",
    "\n",
    "        for l in range(length):\n",
    "            state_tensor = x[:, l, :]\n",
    "            \n",
    "            # Compute output for this step\n",
    "            output[:, l, :], transition_tensor = self.step_coil(state_tensor, transition_tensor)\n",
    "\n",
    "        return output, transition_tensor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence-to-Sequence Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 16\n",
    "batch, length, dim = 13, 64, n_features\n",
    "x = torch.randn(batch, length, dim)\n",
    "model = NeuralCoilLayer(\n",
    "    n_features = n_features\n",
    ")\n",
    "y = model(x)\n",
    "\n",
    "\n",
    "print(y[0].shape)\n",
    "assert y[0].shape == x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 13\n",
    "n = 16\n",
    "slices = 17\n",
    "\n",
    "weights = torch.rand(batch_size,slices)\n",
    "selected_transition_tensors = torch.rand(batch_size, n, n ,slices)\n",
    "\n",
    "selected_transition_tensor = torch.einsum('bs,bjks->bjk', weights,selected_transition_tensors)\n",
    "\n",
    "alt = (selected_transition_tensors * weights.unsqueeze(-2).unsqueeze(-2)).sum(-1)\n",
    "alt3 = (torch.mul(selected_transition_tensors, weights.unsqueeze(-2).unsqueeze(-2))).sum(-1)\n",
    "print(alt3[5,6])\n",
    "print(selected_transition_tensor[5,6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, repeat\n",
    "\n",
    "selected_interaction_tensors = torch.rand(n,n,n,slices)\n",
    "selected_norm_subgroups = torch.rand(batch_size,slices, n)\n",
    "\n",
    "selected_transition_tensors = torch.einsum('ijks,bsi->bjks', selected_interaction_tensors, selected_norm_subgroups)\n",
    "selected_transition_tensors2 = torch.einsum('ijks,bks->bijs', selected_interaction_tensors, selected_norm_subgroups.permute(0,2,1))\n",
    "\n",
    "alt2 = (selected_interaction_tensors * selected_norm_subgroups.permute(0,2,1).unsqueeze(1).unsqueeze(1)).sum(-2)\n",
    "print(alt2.shape)\n",
    "print(selected_transition_tensors[5,6,2])\n",
    "print(selected_transition_tensors2[5,6,2])\n",
    "print(alt2[5,6,2])\n",
    "\n",
    "\n",
    "slicetest = torch.matmul(selected_interaction_tensors[:,:,:,2],selected_norm_subgroups.permute(0,2,1)[1,:,2])\n",
    "print(slicetest[5,9])\n",
    "print(alt2[1,:,:,2][5,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Rearrange selected_norm_subgroups to move the 'i' dimension to the last position\n",
    "selected_norm_subgroups_rearranged = rearrange(selected_norm_subgroups, 'b s i -> (i s) b')\n",
    "\n",
    "# Step 2: Perform matrix multiplication\n",
    "# selected_interaction_tensors shape is assumed to be [..., i, ...], matching 'i' with 's' of rearranged\n",
    "result = rearrange(torch.matmul(rearrange(selected_interaction_tensors, 'i j k s -> j k (i s)'), selected_norm_subgroups_rearranged),'j k b -> b j k')\n",
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j, k = 14, 12, 17\n",
    "\n",
    "tensor_a = torch.rand(i,k)\n",
    "tensor_b = torch.rand(k,j)\n",
    "\n",
    "option1 = torch.matmul(tensor_a, tensor_b)\n",
    "option2 = torch.einsum('ik,kj -> ij',tensor_a, tensor_b)\n",
    "option3 = tensor_a@tensor_b\n",
    "option4 = (tensor_a.unsqueeze(-1) * tensor_b).sum(dim=1)\n",
    "\n",
    "print(option1[5,2])\n",
    "print(option2[5,2])\n",
    "print(option3[5,2])\n",
    "print(option4[5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "with profile(activities=[ProfilerActivity.CPU], record_shapes=True) as prof:\n",
    "    with record_function(\"model_inference\"):\n",
    "        model(x)\n",
    "        \n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consistency Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 4\n",
    "batch, length, dim = 13, 64, n_features\n",
    "x =torch.randn(batch, length, dim)\n",
    "model = NeuralCoilLayer(\n",
    "    n_features = n_features\n",
    ")\n",
    "\n",
    "l = 1\n",
    "state_tensor = x[:, l, :]\n",
    "print(state_tensor[1,:])\n",
    "transition_tensor = torch.randn(batch, n_features, n_features)\n",
    "new_state, new_transition_tensor = model.step_coil(state_tensor, transition_tensor)\n",
    "print(new_state[1,:])\n",
    "new_state, new_transition_tensor = model.step_coil(state_tensor, transition_tensor)\n",
    "print(new_state[1,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be the same as if we just look at the batches independently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 2\n",
    "transition_tensor = transition_tensor[0:2,:,:]\n",
    "l = 1\n",
    "state_tensor = x[0:2, l, :]\n",
    "new_state, new_transition_tensor = model.step_coil(state_tensor, transition_tensor)\n",
    "new_state[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "for step_state in range(100):\n",
    "    state_tensor, transition_tensor = model.step_coil(state_tensor, transition_tensor)\n",
    "    states.append(state_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your data\n",
    "data = [row.to('cpu').detach().numpy() for row in states]\n",
    "# Transpose the data to get 5 traces\n",
    "traces = list(zip(*data))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, trace in enumerate(traces):\n",
    "    plt.plot(trace, label=f'Trace {i+1}')\n",
    "\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def generate_normalized_multivariate_time_series(n_features, total_length, amplitude=1.0):\n",
    "    t = np.linspace(0, 100 * np.pi, total_length)\n",
    "    series = np.zeros((total_length, n_features))\n",
    "    for i in range(n_features):\n",
    "        series[:, i] = amplitude * np.cos(t * (i + 1) / n_features) + 10\n",
    "    \n",
    "    # Normalize such that each timestep's values sum to 1\n",
    "    series_sum = np.sum(series, axis=1, keepdims=True)\n",
    "    series_normalized = series / series_sum\n",
    "    \n",
    "    return series_normalized\n",
    "\n",
    "def segment_time_series(series, length):\n",
    "    # Assuming series is a numpy array of shape [total_length, n_features]\n",
    "    total_length, n_features = series.shape\n",
    "    segments = []\n",
    "    for start in range(0, total_length - length, length):\n",
    "        segment = series[start:start + length]\n",
    "        segments.append(segment)\n",
    "    return np.stack(segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_features = 4\n",
    "length = 64  # Segment length\n",
    "total_length = 1024  # Arbitrary total length for the generated series\n",
    "\n",
    "# Generate and segment the time series\n",
    "series = generate_normalized_multivariate_time_series(n_features, total_length)\n",
    "series_x = series[:-1,]\n",
    "series_y = series[1:,]\n",
    "\n",
    "segments_x = segment_time_series(series_x, length)\n",
    "segments_y = segment_time_series(series_y, length)\n",
    "\n",
    "# Convert to tensors\n",
    "segments_tensor_x = torch.tensor(segments_x, dtype=torch.float)\n",
    "segments_tensor_y = torch.tensor(segments_y, dtype=torch.float)\n",
    "\n",
    "# Prepare inputs and targets\n",
    "X = segments_tensor_x.to(\"cuda\")\n",
    "# Shift segments to the right by one timestep to create the targets\n",
    "Y =  segments_tensor_y.to(\"cuda\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "\n",
    "# Model\n",
    "model = NeuralCoilLayer(\n",
    "    n_features = n_features\n",
    ").to(\"cuda\")\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # Forward pass\n",
    "    outputs, transition_tensor = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "\n",
    "    # Backward and optimize\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_model_output_vs_target(model_outputs, targets, batch_index=0, feature_index=0):\n",
    "    # Extract the specified feature for the given batch from both the model outputs and targets\n",
    "    model_output_series = model_outputs[batch_index, :, feature_index].detach().numpy()\n",
    "    target_series = targets[batch_index, :, feature_index].numpy()\n",
    "    \n",
    "    # Create a range for the x-axis (timesteps)\n",
    "    timesteps = list(range(model_output_series.shape[0]))\n",
    "    \n",
    "    # Create traces\n",
    "    model_trace = go.Scatter(x=timesteps, y=model_output_series, mode='lines', name='Model Output')\n",
    "    target_trace = go.Scatter(x=timesteps, y=target_series, mode='lines', name='Target')\n",
    "    \n",
    "    # Create the figure and add traces\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(model_trace)\n",
    "    fig.add_trace(target_trace)\n",
    "    \n",
    "    # Add title and labels\n",
    "    fig.update_layout(title=f'Model Output vs Target for Feature {feature_index}, Batch {batch_index}',\n",
    "                      xaxis_title='Timestep',\n",
    "                      yaxis_title='Value')\n",
    "    \n",
    "    # Show the figure\n",
    "    fig.show()\n",
    "\n",
    "# Assuming `y` and `Y` are your model outputs and targets, respectively\n",
    "# Adjust batch_index and feature_index as needed\n",
    "plot_model_output_vs_target(outputs.to(\"cpu\"), Y.to(\"cpu\"), batch_index=3, feature_index=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = []\n",
    "batch = 3\n",
    "state_tensor = X[:,0,:]\n",
    "batch_size = 15\n",
    "transition_tensor = torch.zeros(batch_size, n_features, n_features).to(\"cuda\")\n",
    "for step_state in range(300):\n",
    "    state_tensor, transition_tensor = model.step_coil(state_tensor, transition_tensor)\n",
    "    states.append(state_tensor[batch,:])\n",
    "    print(sum(state_tensor[batch,:]))\n",
    "    \n",
    "\n",
    "# Your data\n",
    "data = [row.to('cpu').detach().numpy() for row in states]\n",
    "# Transpose the data to get 5 traces\n",
    "traces = list(zip(*data))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i, trace in enumerate(traces):\n",
    "    plt.plot(trace, label=f'Trace {i+1}')\n",
    "\n",
    "plt.xlabel('Timestep')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coilspy-1sgZ1XBf-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
